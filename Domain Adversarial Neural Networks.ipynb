{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Adversarial Neural Networks (DANN)\n",
    "\n",
    "This is the implementation for the following paper:\n",
    "```\n",
    "@article{ganin2016domain,\n",
    "  title={Domain-adversarial training of neural networks},\n",
    "  author={Ganin, Yaroslav and Ustinova, Evgeniya and Ajakan, Hana and Germain, Pascal and Larochelle, Hugo and Laviolette, Fran{\\c{c}}ois and March, Mario and Lempitsky, Victor},\n",
    "  journal={Journal of machine learning research},\n",
    "  volume={17},\n",
    "  number={59},\n",
    "  pages={1--35},\n",
    "  year={2016}\n",
    "}\n",
    "```\n",
    "\n",
    "The paper is also available [here](./res/Domain-Adversarial%20Training%20of%20Neural%20Networks.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torchinfo import summary\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import _base_model\n",
    "import _dataloader_helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For logging multiple runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "log_root = pathlib.Path(f'./dann')\n",
    "run_id = 1\n",
    "while True:\n",
    "    log_dir = log_root/f'run{run_id}'\n",
    "    if not log_dir.exists():\n",
    "        break\n",
    "    run_id += 1\n",
    "\n",
    "# use a previous run\n",
    "# log_dir = log_root/'run1'\n",
    "log_dir.mkdir(parents=True, exist_ok=True)\n",
    "print(f'Logging to: {log_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare dataset\n",
    "\n",
    "Here, we transform both the source and target datasets into the same size, and repeat the channel dimension for grayscale images, such that both datasets have the same input shape to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (3, 32, 32)\n",
    "num_classes = 10\n",
    "\n",
    "loader_helper = _dataloader_helper.MNIST2USPS(image_size=input_shape[1:])\n",
    "src_train, src_val, src_test = loader_helper.get_src_loaders()\n",
    "tgt_train, tgt_val, tgt_test = loader_helper.get_tgt_loaders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize some samples from both domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 10\n",
    "\n",
    "src_samples = next(iter(src_train))\n",
    "tgt_samples = next(iter(tgt_train))\n",
    "\n",
    "src_images, src_labels = src_samples[0][:num_samples], src_samples[1][:num_samples]\n",
    "tgt_images, tgt_labels = tgt_samples[0][:num_samples], tgt_samples[1][:num_samples]\n",
    "\n",
    "def plot_samples(samples, figsize=(16, 6)):\n",
    "    fig, ax = plt.subplots(1, num_samples, figsize=figsize)\n",
    "    for i in range(num_samples):\n",
    "        ax[i].imshow(np.transpose(samples[i], (1, 2, 0)))\n",
    "        ax[i].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "plot_samples(src_images)\n",
    "print(src_images.shape)\n",
    "print(src_labels)\n",
    "\n",
    "plot_samples(tgt_images)\n",
    "print(tgt_images.shape)\n",
    "print(tgt_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DANN\n",
    "\n",
    "The general architecture of DANN is shown in the figure below:<br>\n",
    "<img src=\"./res/images/dann-overview.png\" width=\"1000\">\n",
    "\n",
    "The objective function of DANN is similar to that of ADDA in the sense that they both contain adversarial terms, in which the label predictor is encouraged to fool the domain classifier and the domain classifier is encouraged to correctly discriminate between the domains. However, DANN performs domain adpatation during the training of the classifier (i.e. end-to-end), while ADDA performs adaptation in a separate step after training the source classifier.\n",
    "\n",
    "The loss function of DANN is defined as follows:\n",
    "\\begin{align*}\n",
    "E(\\theta_f, \\theta_y, \\theta_d) &= \\sum_{i, d_i=0} L_y(G_y(G_f(\\mathbf{x}_i; \\theta_f); \\theta_y), y_i) - \\lambda \\sum_{i} L_d(G_d(G_f(\\mathbf{x}_i; \\theta_f); \\theta_d), d_i) \\\\\n",
    "    &= \\sum_{i, d_i=0} L_y^i(\\theta_f, \\theta_y) - \\lambda \\sum_{i} L_d^i(\\theta_f, \\theta_d)\n",
    "\\end{align*}\n",
    "where $L_y$ is the label prediction loss, $L_d$ is the domain classification loss, $G_f$ is the feature extractor, $G_y$ is the label predictor, and $G_d$ is the domain classifier. And $\\lambda$ is a hyperparameter that balances the two losses.\n",
    "\n",
    "The objective is then to find parameters $\\hat{\\theta}_f$, $\\hat{\\theta}_y$, and $\\hat{\\theta}_d$ such that:\n",
    "\\begin{align*}\n",
    "\\hat{\\theta}_f, \\hat{\\theta}_y &= \\arg\\min_{\\theta_f, \\theta_y} E(\\theta_f, \\theta_y, \\hat{\\theta}_d) \\\\\n",
    "\\hat{\\theta}_d &= \\arg\\max_{\\theta_d} E(\\hat{\\theta}_f, \\hat{\\theta}_y, \\theta_d)\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientReversalF(torch.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, alpha):\n",
    "        ctx.alpha = alpha\n",
    "        return x.view_as(x)\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output.neg() * ctx.alpha, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DANNModel(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.encoder = _base_model.CNNEncoder(\n",
    "            input_shape=input_shape\n",
    "        )\n",
    "        self.cls_head = _base_model.FCHead(\n",
    "            input_shape=self.encoder.output_shape,\n",
    "            op_out_features=num_classes\n",
    "        )\n",
    "        self.domain_cls_head = _base_model.FCHead(\n",
    "            input_shape=self.encoder.output_shape,\n",
    "            op_out_features=2\n",
    "        )\n",
    "    \n",
    "    def forward(self, x, alpha=1):\n",
    "        x = self.encoder(x)\n",
    "        x = torch.flatten(x, start_dim=1)\n",
    "        x_reverse = GradientReversalF.apply(x, alpha)\n",
    "        y_pred = self.cls_head(x)\n",
    "        d_pred = self.domain_cls_head(x_reverse)\n",
    "        return (y_pred, d_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DANNModel(\n",
    "    input_shape=input_shape,\n",
    "    num_classes=num_classes\n",
    ").to(device)\n",
    "\n",
    "summary(model, input_size=(5, *input_shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_loader, loss_fn):\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "\n",
    "    training = model.training\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch, (x, y) in enumerate(val_loader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            y_pred, _ = model(x)\n",
    "            loss = loss_fn(y_pred, y).item()\n",
    "            n_correct = (y_pred.argmax(dim=1) == y).sum().item()\n",
    "            val_loss += loss * x.shape[0]\n",
    "            val_acc += n_correct\n",
    "    model.train(training)\n",
    "    \n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_acc /= len(val_loader.dataset)\n",
    "    return (val_loss, val_acc)\n",
    "\n",
    "def train(\n",
    "    model,\n",
    "    src_loader,\n",
    "    tgt_loader,\n",
    "    src_val_loader,\n",
    "    tgt_val_loader,\n",
    "    optimizer,\n",
    "    loss_fn,\n",
    "    num_steps=20000,\n",
    "    checkpoint=100,\n",
    "):\n",
    "    model.train()\n",
    "\n",
    "    train_stats = []\n",
    "    val_stats = []\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    src_loader_iter = iter(src_loader)\n",
    "    tgt_loader_iter = iter(tgt_loader)\n",
    "\n",
    "    tb_writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    for step in tqdm(range(num_steps)):\n",
    "        try:\n",
    "            src_x, src_y = next(src_loader_iter)\n",
    "        except StopIteration:\n",
    "            src_loader_iter = iter(src_loader)\n",
    "            src_x, src_y = next(src_loader_iter)\n",
    "        try:\n",
    "            tgt_x, tgt_y = next(tgt_loader_iter)\n",
    "        except StopIteration:\n",
    "            tgt_loader_iter = iter(tgt_loader)\n",
    "            tgt_x, tgt_y = next(tgt_loader_iter)\n",
    "        \n",
    "        src_x, src_y = src_x.to(device), src_y.to(device)\n",
    "        tgt_x, tgt_y = tgt_x.to(device), tgt_y.to(device)\n",
    "\n",
    "        alpha = 2 / (1 + np.exp(-10 * step/num_steps)) - 1\n",
    "\n",
    "        src_y_pred, src_d_pred = model(src_x, alpha=alpha)\n",
    "        tgt_y_pred, tgt_d_pred = model(tgt_x, alpha=alpha)\n",
    "\n",
    "        # src domain samples are labeled 0, tgt domain samples are labeled 1\n",
    "        srd_d = torch.full((src_x.shape[0],), fill_value=0, dtype=torch.long, device=device)\n",
    "        tgt_d = torch.full((tgt_x.shape[0],), fill_value=1, dtype=torch.long, device=device)\n",
    "\n",
    "        # note that we do not use tgt_y\n",
    "        src_L_y = loss_fn(src_y_pred, src_y)\n",
    "        src_L_d = loss_fn(src_d_pred, srd_d)\n",
    "        tgt_L_d = loss_fn(tgt_d_pred, tgt_d)\n",
    "        loss = src_L_y + src_L_d + tgt_L_d\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if step % checkpoint == 0:\n",
    "            src_val_loss, src_val_acc = evaluate(model, src_val_loader, loss_fn)\n",
    "            tgt_val_loss, tgt_val_acc = evaluate(model, tgt_val_loader, loss_fn)\n",
    "\n",
    "            train_stats += [[\n",
    "                step,\n",
    "                loss.item(),\n",
    "                src_L_y.item(),\n",
    "                src_L_d.item(),\n",
    "                tgt_L_d.item(),\n",
    "            ]]\n",
    "            val_stats += [[\n",
    "                step,\n",
    "                src_val_loss,\n",
    "                src_val_acc,\n",
    "                tgt_val_loss,\n",
    "                tgt_val_acc,\n",
    "            ]]\n",
    "\n",
    "            tb_writer.add_scalar('train/loss', loss.item(), step)\n",
    "            tb_writer.add_scalar('train/src_L_y', src_L_y.item(), step)\n",
    "            tb_writer.add_scalar('train/src_L_d', src_L_d.item(), step)\n",
    "            tb_writer.add_scalar('train/tgt_L_d', tgt_L_d.item(), step)\n",
    "\n",
    "            tb_writer.add_scalar('val/src_L_y', src_val_loss, step)\n",
    "            tb_writer.add_scalar('val/src_acc', src_val_acc, step)\n",
    "            tb_writer.add_scalar('val/tgt_L_d', tgt_val_loss, step)\n",
    "            tb_writer.add_scalar('val/tgt_acc', tgt_val_acc, step)\n",
    "\n",
    "            # save the best model\n",
    "            # this may be cheating since in reality the target dataset is unlabeled\n",
    "            if tgt_val_loss < best_val_loss:\n",
    "                best_val_loss = tgt_val_loss\n",
    "                torch.save(model.state_dict(), log_dir/'tgt_best_model.pth')\n",
    "\n",
    "    tb_writer.close()\n",
    "\n",
    "    train_stats = np.array(train_stats)\n",
    "    val_stats = np.array(val_stats)\n",
    "    return (train_stats, val_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stats, val_stats = train(\n",
    "    model,\n",
    "    src_train,\n",
    "    tgt_train,\n",
    "    src_val,\n",
    "    tgt_val,\n",
    "    optimizer=torch.optim.Adam(model.parameters(), lr=1e-3, betas=(0.5, 0.9)),\n",
    "    loss_fn=nn.CrossEntropyLoss(),\n",
    "    num_steps=5000,\n",
    "    checkpoint=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 18))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(train_stats[:, 0], train_stats[:, 1], label='src_L_y')\n",
    "plt.plot(train_stats[:, 0], train_stats[:, 2], label='src_L_d')\n",
    "plt.plot(train_stats[:, 0], train_stats[:, 3], label='tgt_L_d')\n",
    "plt.legend()\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Training Loss')\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(val_stats[:, 0], val_stats[:, 1], label='src_val_loss')\n",
    "plt.plot(val_stats[:, 0], val_stats[:, 3], label='tgt_val_loss')\n",
    "plt.legend()\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('loss')\n",
    "plt.title('Validation Loss')\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(val_stats[:, 0], val_stats[:, 2], label='src_val_acc')\n",
    "plt.plot(val_stats[:, 0], val_stats[:, 4], label='tgt_val_acc')\n",
    "plt.legend()\n",
    "plt.xlabel('step')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Validation Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(log_dir/'tgt_best_model.pth'))\n",
    "\n",
    "src_loss, src_acc = evaluate(model, src_test, nn.CrossEntropyLoss())\n",
    "tgt_loss, tgt_acc = evaluate(model, tgt_test, nn.CrossEntropyLoss())\n",
    "\n",
    "print('Adapted model:')\n",
    "print(f'src_test -> loss: {src_loss:.4f}, acc: {src_acc:.4f}')\n",
    "print(f'tgt_test -> loss: {tgt_loss:.4f}, acc: {tgt_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
